{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d225f4fd6b1d4b6ca1372a6809bb9c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_905e49ea24324209b61889ac968c1fdf",
              "IPY_MODEL_1387e0b44922498687e43e0153d4d588",
              "IPY_MODEL_8437c07c71754b8eb74b68263f1d661e"
            ],
            "layout": "IPY_MODEL_70c516d6190e49509da0b76fb90e9fb1"
          }
        },
        "905e49ea24324209b61889ac968c1fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83e178f7246f409cbbaa1c0ac4112cb9",
            "placeholder": "​",
            "style": "IPY_MODEL_726ea922d7d74cdd8c70650aa7c68b75",
            "value": "README.md: "
          }
        },
        "1387e0b44922498687e43e0153d4d588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e962ca6480594a66a609b23a8d90309b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a95460ccac164d32bf3faf87acd98a62",
            "value": 1
          }
        },
        "8437c07c71754b8eb74b68263f1d661e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4079823cd946f58e660863c2568346",
            "placeholder": "​",
            "style": "IPY_MODEL_864c2730bca04bc29371ed7531b516e1",
            "value": " 3.72k/? [00:00&lt;00:00, 611kB/s]"
          }
        },
        "70c516d6190e49509da0b76fb90e9fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e178f7246f409cbbaa1c0ac4112cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726ea922d7d74cdd8c70650aa7c68b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e962ca6480594a66a609b23a8d90309b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a95460ccac164d32bf3faf87acd98a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa4079823cd946f58e660863c2568346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864c2730bca04bc29371ed7531b516e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4368dd53885c47cc8d69d728d3c4f726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ef517ede2814a68b81e542962c01db0",
              "IPY_MODEL_4bbd93105709470b9e9a945d760e25e8",
              "IPY_MODEL_0c8ccf8ae0984b58ae4d39b473ce16af"
            ],
            "layout": "IPY_MODEL_eda77af2a78d4878a8d289051672dd3a"
          }
        },
        "4ef517ede2814a68b81e542962c01db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856822886db04367a3e5ef6fb93ffae1",
            "placeholder": "​",
            "style": "IPY_MODEL_518bbe41dea24c2cb4f779d47653293f",
            "value": "100%"
          }
        },
        "4bbd93105709470b9e9a945d760e25e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719636421cbd40d9ad94d0a52167d16e",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8312e87d52ce4af690cd96d446d2b5cb",
            "value": 25
          }
        },
        "0c8ccf8ae0984b58ae4d39b473ce16af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48119d7fb904411c890f9e810cf7e8a1",
            "placeholder": "​",
            "style": "IPY_MODEL_defde17105c34007a45949b1e34914ba",
            "value": " 25/25 [00:01&lt;00:00, 15.26it/s]"
          }
        },
        "eda77af2a78d4878a8d289051672dd3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856822886db04367a3e5ef6fb93ffae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518bbe41dea24c2cb4f779d47653293f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "719636421cbd40d9ad94d0a52167d16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8312e87d52ce4af690cd96d446d2b5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48119d7fb904411c890f9e810cf7e8a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "defde17105c34007a45949b1e34914ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgA7yYZlF4CE",
        "outputId": "1c552afc-7d8c-4126-ab65-f992de7b274e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/488.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.6/221.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cpu\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Installation & Imports\n",
        "!pip install -q sentence-transformers datasets scipy networkx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy.stats import norm\n",
        "from tqdm.auto import tqdm\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Running on {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the mathematical core of ANMI:SparseELOEstimator: Estimates global ELO scores from sparse pairwise comparisons ($O(n)$ complexity).ELOGapSelector: Determines if a negative is \"Safe\", \"Hard\", or \"Dangerous\" based on the ELO gap."
      ],
      "metadata": {
        "id": "jCHAMbOSGAnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Core ANMI Engine (ELO & Selection) - FIXED\n",
        "\n",
        "class SparseELOEstimator:\n",
        "    \"\"\"\n",
        "    Estimates ELO scores.\n",
        "    OPTIMIZED: Uses Pointwise scoring -> Pairwise difference.\n",
        "    This is O(N) instead of O(K*N), making it much faster for the CrossEncoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, k=4, max_iter=50, tol=1e-4):\n",
        "        self.k = k\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "\n",
        "    def estimate(self, documents: List[str], query: str, pairwise_model) -> Dict[int, float]:\n",
        "        n = len(documents)\n",
        "        if n < 2: return {0: 1200.0}\n",
        "\n",
        "        # 1. Score all documents directly (Pointwise)\n",
        "        # This fixes the \"3 arguments\" issue by only sending [Query, Doc]\n",
        "        pairs_to_score = [[query, doc] for doc in documents]\n",
        "\n",
        "        # Returns raw logits/scores (unbounded)\n",
        "        scores = pairwise_model.predict(pairs_to_score, batch_size=32, show_progress_bar=False)\n",
        "\n",
        "        # 2. Build k-regular graph for ELO calculation\n",
        "        # Even though we have exact scores, we simulate the graph structure\n",
        "        # to maintain the ANMI theoretical sparse constraint (or we can just use scores directly)\n",
        "\n",
        "        # Since we have pointwise scores, we can actually skip the iterative Thurstone\n",
        "        # solver and map scores directly to ELO if we assume transitivity.\n",
        "        # However, to keep the graph-theory component:\n",
        "\n",
        "        edges = set()\n",
        "        indices = list(range(n))\n",
        "        for _ in range(max(1, self.k // 2)):\n",
        "            np.random.shuffle(indices)\n",
        "            for i in range(n):\n",
        "                u, v = indices[i], indices[(i + 1) % n]\n",
        "                edges.add(tuple(sorted((u, v))))\n",
        "        edge_list = list(edges)\n",
        "\n",
        "        # 3. Fit ELO\n",
        "        elo_scores = np.zeros(n)\n",
        "        lr = 1.0\n",
        "\n",
        "        for it in range(self.max_iter):\n",
        "            grad = np.zeros(n)\n",
        "            for u, v in edge_list:\n",
        "                # Derive pairwise preference from pointwise score difference\n",
        "                # P(u > v) = sigmoid(s_u - s_v)\n",
        "                diff = scores[u] - scores[v]\n",
        "                w_uv = 1 / (1 + np.exp(-diff))\n",
        "\n",
        "                delta = elo_scores[u] - elo_scores[v]\n",
        "                sigma = 1 / (1 + np.exp(-delta))\n",
        "\n",
        "                g = w_uv - sigma\n",
        "                grad[u] += g\n",
        "                grad[v] -= g\n",
        "\n",
        "            grad -= np.mean(grad)\n",
        "            if np.max(np.abs(grad)) < self.tol: break\n",
        "            elo_scores += lr * grad\n",
        "            lr *= 0.9\n",
        "\n",
        "        elo_scores = (elo_scores - np.mean(elo_scores)) * 400 + 1200\n",
        "        return {i: s for i, s in enumerate(elo_scores)}\n",
        "\n",
        "\n",
        "class ELOGapSelector:\n",
        "    \"\"\"\n",
        "    Selects negatives based on ELO gap from positive.\n",
        "    Gap = Positive_ELO - Negative_ELO\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.danger_zone = 50    # Gap < 50: Too risky\n",
        "        self.hard_zone = 200     # 50-200: Hard negative\n",
        "        self.easy_zone = 400     # > 400: Easy negative\n",
        "\n",
        "    def weight(self, pos_elo, neg_elo):\n",
        "        gap = pos_elo - neg_elo\n",
        "        if gap < self.danger_zone: return 0.0\n",
        "        if gap < self.hard_zone: return 1.0\n",
        "        if gap < self.easy_zone: return 0.5\n",
        "        return 0.1"
      ],
      "metadata": {
        "id": "aC6l80oDF-IA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This implements the Fixed Hybrid Loss discussed in the critique. It includes a learnable elo_head to map dot-products to ELO space, preventing gradient scale mismatch."
      ],
      "metadata": {
        "id": "Qi9ds6SXGRJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. ANMI Hybrid Loss Function\n",
        "\n",
        "class ANMIHybridLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.6, tau=0.07):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Mixing coef (0.6 means 60% InfoNCE, 40% MSE)\n",
        "        self.tau = tau\n",
        "        # Learnable projection: DotProduct -> ELO Space\n",
        "        self.elo_head = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, q_emb, p_emb, n_embs, n_weights, n_elos, p_elo):\n",
        "        \"\"\"\n",
        "        q_emb: [B, Dim]\n",
        "        p_emb: [B, Dim]\n",
        "        n_embs: [B, K, Dim]\n",
        "        n_weights: [B, K] (ELO-derived weights)\n",
        "        n_elos: [B, K] (Target ELOs)\n",
        "        p_elo: [B] (Target Positive ELO)\n",
        "        \"\"\"\n",
        "        B, K, D = n_embs.shape\n",
        "\n",
        "        # 1. Compute Dot Products (Sim Scores)\n",
        "        p_sim = torch.sum(q_emb * p_emb, dim=-1, keepdim=True) # [B, 1]\n",
        "        n_sim = torch.bmm(n_embs, q_emb.unsqueeze(-1)).squeeze(-1) # [B, K]\n",
        "\n",
        "        # === COMPONENT A: Weighted InfoNCE ===\n",
        "        # Denominator: exp(p/tau) + sum(w_i * exp(n_i/tau))\n",
        "        # Note: We detach weights to prevent backprop through the ELO engine\n",
        "        p_exp = torch.exp(p_sim / self.tau)\n",
        "        n_exp = torch.exp(n_sim / self.tau) * n_weights.to(q_emb.device)\n",
        "\n",
        "        loss_nce = -torch.log(p_exp / (p_exp + n_exp.sum(dim=-1, keepdim=True)))\n",
        "\n",
        "        # === COMPONENT B: ELO MSE (Regularization) ===\n",
        "        # Project all scores to ELO space\n",
        "        all_sims = torch.cat([p_sim, n_sim], dim=1) # [B, K+1]\n",
        "        all_elos = torch.cat([p_elo.unsqueeze(1), n_elos], dim=1).to(q_emb.device)\n",
        "\n",
        "        # Learnable mapping applied to similarity scores\n",
        "        pred_elos = self.elo_head(all_sims.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Normalize ELO targets for numerical stability (Standard Scaler approx)\n",
        "        target_elos = (all_elos - 1200) / 400\n",
        "        pred_elos_norm = (pred_elos - 1200) / 400\n",
        "\n",
        "        loss_mse = F.mse_loss(pred_elos_norm, target_elos)\n",
        "\n",
        "        # Combine\n",
        "        return self.alpha * loss_nce.mean() + (1 - self.alpha) * loss_mse"
      ],
      "metadata": {
        "id": "m6vWQPwUGSLm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make this run instantly without massive downloads, we generate a synthetic \"Technical Support\" dataset.\n",
        "\n",
        "Concepts: Python, SQL, Java, AWS.\n",
        "\n",
        "Logic: A query about \"Python\" should match a doc about \"Python\".\n",
        "\n",
        "Hard Negative: A doc about \"Java\" (both are code, but wrong language)."
      ],
      "metadata": {
        "id": "R6HFLRdEGV9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Generate Synthetic Dataset (Micro-Corpus)\n",
        "\n",
        "def generate_micro_corpus():\n",
        "    topics = [\"Python\", \"Java\", \"SQL\", \"AWS\", \"Docker\"]\n",
        "    actions = [\"install\", \"debug\", \"configure\", \"deploy\", \"optimize\"]\n",
        "    corpus = []\n",
        "    queries = []\n",
        "    ground_truth = {} # query_idx -> pos_doc_idx\n",
        "\n",
        "    print(\"Generating synthetic data...\")\n",
        "\n",
        "    # Create Documents\n",
        "    doc_id = 0\n",
        "    for t in topics:\n",
        "        for a in actions:\n",
        "            # Create 5 variations per topic-action pair\n",
        "            for i in range(5):\n",
        "                text = f\"Guide to {a} {t} in production environment version {i}.\"\n",
        "                corpus.append(text)\n",
        "                doc_id += 1\n",
        "\n",
        "    # Create Queries\n",
        "    q_id = 0\n",
        "    for t in topics:\n",
        "        for a in actions:\n",
        "            text = f\"How do I {a} {t}?\"\n",
        "            queries.append(text)\n",
        "            # Assign a random positive from the correct topic/action group\n",
        "            # Simple heuristic: find docs containing both keywords\n",
        "            candidates = [i for i, d in enumerate(corpus) if t in d and a in d]\n",
        "            ground_truth[q_id] = candidates[0] # Pick first as \"True Positive\"\n",
        "            q_id += 1\n",
        "\n",
        "    print(f\"Generated {len(corpus)} docs and {len(queries)} queries.\")\n",
        "    return corpus, queries, ground_truth\n",
        "\n",
        "corpus, queries, ground_truth = generate_micro_corpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eInaDVTEGWdo",
        "outputId": "c66bea29-ae66-4604-834c-7e669c4b0758"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic data...\n",
            "Generated 125 docs and 25 queries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the heavy lifting. We use a Cross-Encoder to find hard negatives and assign ELO scores.\n",
        "\n",
        "Miner: Simple Dense Retrieval (using a tiny model for speed).\n",
        "\n",
        "Oracle: cross-encoder/ms-marco-TinyBERT-L-2 (Small but effective)."
      ],
      "metadata": {
        "id": "CCOnxbAXGcdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Phase 1: Offline Mining & ELO Estimation - FIXED\n",
        "\n",
        "from sentence_transformers import CrossEncoder # <--- THIS WAS MISSING\n",
        "\n",
        "# 1. Setup Models\n",
        "print(\"Loading models...\")\n",
        "# Fast bi-encoder for candidate generation\n",
        "retriever = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "# Oracle: Use CrossEncoder class, NOT SentenceTransformer\n",
        "oracle = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-2', device=device)\n",
        "\n",
        "# 2. Encode Corpus (Offline Indexing)\n",
        "print(\"Encoding corpus...\")\n",
        "corpus_embs = retriever.encode(corpus, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "# 3. Mining Loop\n",
        "elo_engine = SparseELOEstimator(k=6)\n",
        "selector = ELOGapSelector()\n",
        "\n",
        "training_data = []\n",
        "\n",
        "print(\"Starting Mining Phase...\")\n",
        "for q_idx, query_text in tqdm(enumerate(queries), total=len(queries)):\n",
        "    pos_doc_idx = ground_truth[q_idx]\n",
        "    pos_doc_text = corpus[pos_doc_idx]\n",
        "\n",
        "    # A. Retrieve Candidates (Top-20)\n",
        "    q_emb = retriever.encode(query_text, convert_to_tensor=True)\n",
        "    hits = util.semantic_search(q_emb, corpus_embs, top_k=20)[0]\n",
        "    candidate_indices = [h['corpus_id'] for h in hits]\n",
        "\n",
        "    if pos_doc_idx not in candidate_indices:\n",
        "        candidate_indices.append(pos_doc_idx)\n",
        "\n",
        "    # Get texts\n",
        "    candidate_texts = [corpus[i] for i in candidate_indices]\n",
        "\n",
        "    # B. Estimate ELO Scores (The Oracle Step)\n",
        "    elo_map = elo_engine.estimate(candidate_texts, query_text, oracle)\n",
        "\n",
        "    # Map back to global indices\n",
        "    doc_elos = {candidate_indices[i]: score for i, score in elo_map.items()}\n",
        "    pos_elo = doc_elos[pos_doc_idx]\n",
        "\n",
        "    # C. Select & Weight Negatives\n",
        "    negatives = []\n",
        "    neg_weights = []\n",
        "    neg_elos = []\n",
        "\n",
        "    for idx in candidate_indices:\n",
        "        if idx == pos_doc_idx: continue\n",
        "\n",
        "        elo = doc_elos[idx]\n",
        "        weight = selector.weight(pos_elo, elo)\n",
        "\n",
        "        if weight > 0:\n",
        "            negatives.append(corpus[idx])\n",
        "            neg_weights.append(weight)\n",
        "            neg_elos.append(elo)\n",
        "\n",
        "    if len(negatives) > 0:\n",
        "        training_data.append({\n",
        "            \"query\": query_text,\n",
        "            \"positive\": pos_doc_text,\n",
        "            \"negatives\": negatives[:8],\n",
        "            \"neg_weights\": neg_weights[:8],\n",
        "            \"neg_elos\": neg_elos[:8],\n",
        "            \"pos_elo\": pos_elo\n",
        "        })\n",
        "\n",
        "print(f\"Mining complete. Created {len(training_data)} curated training examples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "d225f4fd6b1d4b6ca1372a6809bb9c13",
            "905e49ea24324209b61889ac968c1fdf",
            "1387e0b44922498687e43e0153d4d588",
            "8437c07c71754b8eb74b68263f1d661e",
            "70c516d6190e49509da0b76fb90e9fb1",
            "83e178f7246f409cbbaa1c0ac4112cb9",
            "726ea922d7d74cdd8c70650aa7c68b75",
            "e962ca6480594a66a609b23a8d90309b",
            "a95460ccac164d32bf3faf87acd98a62",
            "fa4079823cd946f58e660863c2568346",
            "864c2730bca04bc29371ed7531b516e1",
            "4368dd53885c47cc8d69d728d3c4f726",
            "4ef517ede2814a68b81e542962c01db0",
            "4bbd93105709470b9e9a945d760e25e8",
            "0c8ccf8ae0984b58ae4d39b473ce16af",
            "eda77af2a78d4878a8d289051672dd3a",
            "856822886db04367a3e5ef6fb93ffae1",
            "518bbe41dea24c2cb4f779d47653293f",
            "719636421cbd40d9ad94d0a52167d16e",
            "8312e87d52ce4af690cd96d446d2b5cb",
            "48119d7fb904411c890f9e810cf7e8a1",
            "defde17105c34007a45949b1e34914ba"
          ]
        },
        "id": "4cleKXyNGc9F",
        "outputId": "3eb8e4a7-f593-4c80-bf8b-24fb2c8b6190"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d225f4fd6b1d4b6ca1372a6809bb9c13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding corpus...\n",
            "Starting Mining Phase...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4368dd53885c47cc8d69d728d3c4f726"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mining complete. Created 25 curated training examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train a new model from scratch using the mined data. Notice how simple this loop is because all the heavy calculation (validation, weighting) happened in Phase 1"
      ],
      "metadata": {
        "id": "hp10dtckGgcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Phase 2: Online Training (ANMI)\n",
        "\n",
        "# Initialize a fresh Student Model\n",
        "student_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "# Add a linear projection head for ELO MSE\n",
        "criterion = ANMIHybridLoss(alpha=0.5).to(device)\n",
        "optimizer = torch.optim.AdamW(list(student_model.parameters()) + list(criterion.parameters()), lr=2e-5)\n",
        "\n",
        "# Simple Collate Function for padding\n",
        "def collate_fn(batch):\n",
        "    queries = [b['query'] for b in batch]\n",
        "    positives = [b['positive'] for b in batch]\n",
        "    # Flatten negatives for encoding, reshape later\n",
        "    negatives = [n for b in batch for n in b['negatives']]\n",
        "\n",
        "    # Prepare Tensors\n",
        "    weights = torch.tensor([b['neg_weights'] for b in batch], dtype=torch.float)\n",
        "    neg_elos = torch.tensor([b['neg_elos'] for b in batch], dtype=torch.float)\n",
        "    pos_elos = torch.tensor([b['pos_elo'] for b in batch], dtype=torch.float)\n",
        "\n",
        "    return queries, positives, negatives, weights, neg_elos, pos_elos\n",
        "\n",
        "# Dataloader\n",
        "loader = DataLoader(training_data, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "print(\"Starting ANMI Training...\")\n",
        "student_model.train()\n",
        "\n",
        "for epoch in range(20): # Fast training\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        q_txt, p_txt, n_txt, weights, n_elos, p_elos = batch\n",
        "\n",
        "        # 1. Forward Pass (Student)\n",
        "        q_emb = student_model.encode(q_txt, convert_to_tensor=True)\n",
        "        p_emb = student_model.encode(p_txt, convert_to_tensor=True)\n",
        "        n_embs_flat = student_model.encode(n_txt, convert_to_tensor=True)\n",
        "\n",
        "        # Reshape negatives [B * K, D] -> [B, K, D]\n",
        "        # Note: In real production, handle variable num negatives via masking\n",
        "        # Here we assume fixed size for demo simplicity or truncate\n",
        "        k = len(n_txt) // len(q_txt)\n",
        "        n_embs = n_embs_flat.view(len(q_txt), k, -1)\n",
        "\n",
        "        # 2. Compute Hybrid Loss\n",
        "        loss = criterion(q_emb, p_emb, n_embs, weights, n_elos, p_elos)\n",
        "\n",
        "        # 3. Update\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(loader):.4f}\")\n",
        "\n",
        "print(\"Training finished!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBZP6rCGGg2D",
        "outputId": "975af4c8-e312-41e1-8916-62dfe368b1cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ANMI Training...\n",
            "Epoch 1: Loss = 4.5594\n",
            "Epoch 2: Loss = 4.5362\n",
            "Epoch 3: Loss = 4.5363\n",
            "Epoch 4: Loss = 4.5896\n",
            "Epoch 5: Loss = 4.4987\n",
            "Epoch 6: Loss = 4.5148\n",
            "Epoch 7: Loss = 4.5272\n",
            "Epoch 8: Loss = 4.5272\n",
            "Epoch 9: Loss = 4.5363\n",
            "Epoch 10: Loss = 4.4603\n",
            "Epoch 11: Loss = 4.5896\n",
            "Epoch 12: Loss = 4.5099\n",
            "Epoch 13: Loss = 4.5362\n",
            "Epoch 14: Loss = 4.4614\n",
            "Epoch 15: Loss = 4.5261\n",
            "Epoch 16: Loss = 4.4578\n",
            "Epoch 17: Loss = 4.5261\n",
            "Epoch 18: Loss = 4.4744\n",
            "Epoch 19: Loss = 4.4554\n",
            "Epoch 20: Loss = 4.4578\n",
            "Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's verify that the model actually learned to rank relevant documents higher."
      ],
      "metadata": {
        "id": "2r-WxGinGjo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Validation / Inference\n",
        "\n",
        "student_model.eval()\n",
        "\n",
        "# Test Query\n",
        "test_query = \"How do I configure Docker?\"\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "\n",
        "# Encode\n",
        "q_emb = student_model.encode(test_query, convert_to_tensor=True)\n",
        "doc_embs = student_model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Search\n",
        "hits = util.semantic_search(q_emb, doc_embs, top_k=3)[0]\n",
        "\n",
        "print(\"Top Results:\")\n",
        "for i, hit in enumerate(hits):\n",
        "    print(f\"{i+1}. {corpus[hit['corpus_id']]} (Score: {hit['score']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmACKZerGkE0",
        "outputId": "dc1eee6b-0247-49aa-fee0-67e60e92bdb5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do I configure Docker?\n",
            "\n",
            "Top Results:\n",
            "1. Guide to configure Docker in production environment version 3. (Score: 0.7963)\n",
            "2. Guide to configure Docker in production environment version 1. (Score: 0.7940)\n",
            "3. Guide to configure Docker in production environment version 4. (Score: 0.7888)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k13VJiQ9Hs0E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}